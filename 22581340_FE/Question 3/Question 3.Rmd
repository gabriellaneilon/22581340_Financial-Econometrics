---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Question 3: Portfolio Construction"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Gabriella Neilon"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University" # First Author's Affiliation
Email1: "22581340\\@sun.ac.za" # First Author's Email address

# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.
# 
# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"

CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
#Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
    This article examines the methodologies of the SWIX and ALSI indexes, focusing on various aspects such as size indexes (large, mid, and small caps), sector exposures, and stock concentration over time. Using a comprehensive analysis of Exchange Rate data, it highlights the differences in return profiles of both methodologies during periods of currency performance and volatility.
    
    Additionally, the study responds to the JSEâ€™s inquiry on the impact of applying different capping levels (e.g., 5%, 10%, and uncapped) to the SWIX and ALSI. Utilizing data from Rebalance days.rds to identify past quarterly rebalances, it assesses the effects of various capping levels on both indexes.
    
    Key findings reveal that Large Capped funds tend to outperform Mid and Small Capped Funds, albeit demonstrating higher overall volatility. Furthermore, the ALSI generally outperforms the SWIX in terms of returns, although both exhibit relatively similar volatility levels. Notably, within the SWIX index, the returns of Large and Mid capped funds demonstrate close alignment, suggesting a correlation in their performance trends.
    
    Moreover, the research highlights that both SWIX and ALSI encounter increased volatility during periods of high exchange rate volatility, with SWIX displaying more significant effects than ALSI. This pattern remains consistent even during low volatility periods.
    
    Interestingly, ALSI exhibits higher sensitivity to capping constraints compared to SWIX. Despite this, ALSI consistently outperforms SWIX across various restrictions. This suggests that ALSI might require more nuanced management or adjustments to adhere to specific limitations without compromising its performance.
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

library(tidyverse)
library(zoo)
library("RcppRoll")
library(fmxdat)
if (!require("rmsfuns")) install.packages("rmsfuns")
library(rmsfuns)
library(tidyverse)
pacman::p_load(tbl2xts)
library(truncdist)
library(rportfolios)
library(rmsfuns)
pacman::p_load("tidyr", "tbl2xts","devtools","lubridate", "readr", "PerformanceAnalytics", "ggplot2", "dplyr")
pacman::p_load("tidyverse", "devtools", "FactoMineR", "factoextra", "broom", "rmsfuns")
library(rmsfuns)
load_pkg("PerformanceAnalytics")
pacman::p_load("tbl2xts")
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics", 
    "lubridate", "glue")

library(ggExtra)
library(MTS)
library(gt)
```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->


# Basic comparison of different 'Capped' funds for ALSI and SWIX
The data showcases that Large Capped funds outperform both Mid and Small Capped Funds, although they also tend to demonstrate higher overall volatility. Within the ALSI index, the returns exceed those observed in the SWIX index. However, both ALSI and SWIX exhibit relatively similar volatility.

Regarding the SWIX index, the returns of Large and Mid capped funds seem to be more closely aligned with each other. This suggests a degree of correlation or similarity in the performance trend between the Large and Mid capped funds within the SWIX index.

## ALSI
```{r}
# Loading data
ALSI <- read_rds("/Users/gabriellaneilon/Library/Mobile Documents/com~apple~CloudDocs/Masters/Data_23/ALSI.rds")
RebDays <- read_rds("/Users/gabriellaneilon/Library/Mobile Documents/com~apple~CloudDocs/Masters/Data_23/Rebalance_days.rds")
Monthly_ZAR <- read_rds("/Users/gabriellaneilon/Library/Mobile Documents/com~apple~CloudDocs/Masters/Data_23/Monthly_zar.rds")

#Load functions
source("code/Perf_Comparison.R")
source("code/optimum_foo.R")
source("code/Prop_Cap_Foo.R")
source("code/Prop_Cap_Foo.R")
source("code/rebalance_returns.R")

clean_ALSI <- na.omit(ALSI)
# #
# 

#J203 (ALSI)


ALSI_filter<- clean_ALSI %>%
    group_by(Index_Name,date) %>% 
  summarize(ALSI = sum(Return * J203) / sum(J203)) %>%
  ungroup() 

ALSI_new<- ALSI_filter %>% tbl_xts(., cols_to_xts = ALSI, spread_by = Index_Name)

chart.CumReturns(ALSI_new,main = "Cumulative Returns",  legend.loc="bottomright")
```


```{r}
chart.RollingPerformance(R=ALSI_new,
                         
                         FUN="sd",
                         
                         width=30, 
                         
                         main="Rolling 30-day Standard Deviation", 
                         
                         legend.loc="bottomright")
```

## SWIX
```{r}
#J403(SWIX)
SWIX_filter<- clean_ALSI %>%
    group_by(Index_Name,date) %>% 
  summarize(SWIX = sum(Return * J403) / sum(J403)) %>%
  ungroup() 

SWIX_new<- SWIX_filter %>% tbl_xts(., cols_to_xts = SWIX, spread_by = Index_Name)

chart.CumReturns(SWIX_new,main = "Cumulative Returns",  legend.loc="bottomright")
```


```{r}
chart.RollingPerformance(R=SWIX_new,
                         
                         FUN="sd",
                         
                         width=30, 
                         
                         main="Rolling 30-day Standard Deviation", 
                         
                         legend.loc="bottomright")



```

# Periods of high and low volatility

```{r}
Weighted_ALSI <- clean_ALSI %>%
  group_by(date) %>%
  summarize(ALSI = sum(Return * J203) / sum(J203)) %>%
  ungroup() %>% mutate(YM = format(date, "%Y%B")) %>% group_by(YM) %>% 
  filter(date == last(date)) %>% arrange(date) %>% 
  ungroup() 

Weighted_SWIX <- clean_ALSI %>%
  group_by(date) %>%
  summarize(SWIX = sum(Return * J403) / sum(J403)) %>%
  ungroup() %>% mutate(YM = format(date, "%Y%B")) %>% group_by(YM) %>% 
  filter(date == last(date)) %>% arrange(date) %>% 
  ungroup() 

all_weighted <- merge(Weighted_ALSI, Weighted_SWIX) %>% select(-YM) %>% gather("Index", "Return",-date)

ZAR.USD <- Monthly_ZAR  %>% tbl_xts(., cols_to_xts = value, spread_by = Tickers) %>% xts_tbl()%>%  mutate(ZAR.USD.Return=X.ZAR.USD/lag(X.ZAR.USD)-1) %>% select(-X.ZAR.USD) %>% gather("Index", "Return",-date)


all_data <- rbind(all_weighted, ZAR.USD )



Idxs <- na.omit(all_data)

Idxs <-
    
    Idxs %>% 
    mutate(Year = format(date, "%Y")) %>% 
    
    group_by(Index) %>% 
    
    mutate(Top = quantile(Return, 0.99), Bot = quantile(Return, 0.01)) %>% 
    
    mutate(Return = ifelse(Return > Top, Top, 
                        
                        ifelse(Return< Bot, Bot, Return))) %>% ungroup()

ZARSD <- ZAR.USD %>% 
    filter(date>lubridate::ymd(20130101)) %>% #to match the index data
    mutate(Year = format(date, "%Y")) %>% #we have montly data so we need to look at yearly rather
    arrange(date) %>% 
    group_by(Year) %>% summarise(SD = sd(Return)*sqrt(12)) %>% 
    
    # Top Decile Quantile overall (highly volatile month for ZAR:
    mutate(TopQtile = quantile(SD, 0.8, na.rm = TRUE),
           
           BotQtile = quantile(SD, 0.2, na.rm = TRUE))



Hi_Vol <- ZARSD %>% filter(SD > TopQtile) %>% pull(Year)

Low_Vol <- ZARSD %>% filter(SD < BotQtile) %>% pull(Year)

Perf_comparisons <- function(Idxs, Ys, Alias){
   
    Unconditional_SD <- 
        
        Idxs %>% 
        
        group_by(Index) %>% 
        
        mutate(Full_SD = sd(Return) * sqrt(12)) %>% 
        
        filter(Year %in% Ys) %>% 
        
        summarise(SD = sd(Return) * sqrt(12), across(.cols = starts_with("Full"), .fns = max)) %>% 
        
        arrange(desc(SD)) %>% mutate(Period = Alias) %>% 
        
        group_by(Index) %>% 
        
        mutate(Ratio = SD / Full_SD)
    
    Unconditional_SD
    
}

perf_hi <- Perf_comparisons(Idxs, Ys = Hi_Vol, Alias = "High_Vol")

perf_lo <- Perf_comparisons(Idxs, Ys = Low_Vol, Alias = "Low_Vol")

print(perf_hi)
```

```{r}
print(perf_lo)
```
These tables demonstrates that during periods of high exchange rate volatility, both SWIX and ALSI experience increased volatility, with SWIX being more significantly affected compared to ALSI. This pattern holds true during low volatility periods as well.

# Capping
```{r}

#start with J403
Rebalance_days <- RebDays %>% 
    filter(Date_Type == "Reb Trade Day") %>% 
    pull(date)

rebalance_col_ALSI <- clean_ALSI %>%
    rename("weight"= "J403") %>% #the functions use weight so this makes it easier for me later on
    filter(date %in% Rebalance_days ) %>% 
    mutate(RebalanceTime = format(date, "%Y%B%A")) %>% 
    group_by(RebalanceTime) %>% 
    arrange(desc(weight)) %>% 
    ungroup() %>% 
    arrange(date) %>% 
    select(date, Tickers, weight, RebalanceTime )

rebalance_col_SWIX <- clean_ALSI %>%
    rename("weight"= "J403") %>% #the functions use weight so this makes it easier for me later on
    filter(date %in% Rebalance_days ) %>% 
    mutate(RebalanceTime = format(date, "%Y%B%A")) %>% 
    group_by(RebalanceTime) %>% 
    arrange(desc(weight)) %>% 
    ungroup() %>% 
    arrange(date) %>% 
    select(date, Tickers, weight, RebalanceTime )

# Function from class
Proportional_Cap_Foo <- function(df_Cons, W_Cap = 0.08){
  
  # Let's require a specific form from the user... Alerting when it does not adhere this form
  if( !"weight" %in% names(df_Cons)) stop("... for Calc capping to work, provide weight column called 'weight'")
  
  if( !"date" %in% names(df_Cons)) stop("... for Calc capping to work, provide date column called 'date'")
  
  if( !"Tickers" %in% names(df_Cons)) stop("... for Calc capping to work, provide id column called 'Tickers'")

  # First identify the cap breachers...
  Breachers <- 
    df_Cons %>% filter(weight > W_Cap) %>% pull(Tickers)
  
  # Now keep track of breachers, and add to it to ensure they remain at 10%:
  if(length(Breachers) > 0) {
    
    while( df_Cons %>% filter(weight > W_Cap) %>% nrow() > 0 ) {
      
      
      df_Cons <-
        
        bind_rows(
          
          df_Cons %>% filter(Tickers %in% Breachers) %>% mutate(weight = W_Cap),
          
          df_Cons %>% filter(!Tickers %in% Breachers) %>% 
            mutate(weight = (weight / sum(weight, na.rm=T)) * (1-length(Breachers)*W_Cap) )
          
        )
      
      Breachers <- c(Breachers, df_Cons %>% filter(weight > W_Cap) %>% pull(Tickers))
      
    }

    if( sum(df_Cons$weight, na.rm=T) > 1.001 | sum(df_Cons$weight, na.rm=T) < 0.999 | max(df_Cons$weight, na.rm = T) > W_Cap) {
      
      stop( glue::glue("For the Generic weight trimming function used: the weight trimming causes non unit 
      summation of weights for date: {unique(df_Cons$date)}...\n
      The restriction could be too low or some dates have extreme concentrations...") )
      
    }
    
  } else {
    
  }
  
  df_Cons
  
  }
  
#Test to see if function works
# Now, to map this across all the dates, we can use purrr::map_df as follows:
  Capped_df_ALSI <- 
    
    rebalance_col_ALSI%>% 
    # Split our df into groups (where the groups here are the rebalance dates:
    group_split(RebalanceTime) %>% 
    
    # Apply the function Proportional_Cap_Foo to each rebalancing date:
    map_df(~Proportional_Cap_Foo(., W_Cap = 0.08) ) %>% select(-RebalanceTime)
  
  
  Capped_df_SWIX <- 
    
    rebalance_col_SWIX %>% 
    # Split our df into groups (where the groups here are the rebalance dates:
    group_split(RebalanceTime) %>% 
    
    # Apply the function Proportional_Cap_Foo to each rebalancing date:
    map_df(~Proportional_Cap_Foo(., W_Cap = 0.08) ) %>% select(-RebalanceTime) 






```


```{r}
#Function to do everything
library(tidyverse)
library(rmsfuns)

rebalance_returns <- function(data, fund_name, w_cap) {
    rebalance_col <- data %>%
        rename("weight" = {{ fund_name }}) %>%
        filter(date %in% Rebalance_days) %>%
        mutate(RebalanceTime = format(date, "%Y%B%A")) %>%
        group_by(RebalanceTime) %>%
        arrange(desc(weight)) %>%
        ungroup() %>%
        arrange(date) %>%
        select(date, Tickers, weight, RebalanceTime)
    
    # df_Cons <- rebalance_col %>% filter(date == first(date))
    # W_Cap = 0.8
    Proportional_Cap_Foo <- function(df_Cons, W_Cap = 0.05){
        
        # Let's require a specific form from the user... Alerting when it does not adhere this form
        if( !"weight" %in% names(df_Cons)) stop("... for Calc capping to work, provide weight column called 'weight'")
        
        if( !"date" %in% names(df_Cons)) stop("... for Calc capping to work, provide date column called 'date'")
        
        if( !"Tickers" %in% names(df_Cons)) stop("... for Calc capping to work, provide id column called 'Tickers'")
        
        # First identify the cap breachers...
        Breachers <-
            df_Cons %>% filter(weight > W_Cap) %>% pull(Tickers)
        
        # Now keep track of breachers, and add to it to ensure they remain at 10%:
        if(length(Breachers) > 0) {
            
            while( df_Cons %>% filter(weight > W_Cap) %>% nrow() > 0 ) {
                
                
                df_Cons <-
                    
                    bind_rows(
                        
                        df_Cons %>% filter(Tickers %in% Breachers) %>% mutate(weight = W_Cap),
                        
                        df_Cons %>% filter(!Tickers %in% Breachers) %>%
                            mutate(weight = (weight / sum(weight, na.rm=T)) * (1-length(Breachers)*W_Cap) )
                        
                    )
                
                Breachers <- c(Breachers, df_Cons %>% filter(weight > W_Cap) %>% pull(Tickers))
                
            }
            
            if( sum(df_Cons$weight, na.rm=T) > 1.001 | sum(df_Cons$weight, na.rm=T) < 0.999 | max(df_Cons$weight, na.rm = T) > W_Cap) {
                
                stop( glue::glue("For the Generic weight trimming function used: the weight trimming causes non unit
      summation of weights for date: {unique(df_Cons$date)}...\n
      The restriction could be too low or some dates have extreme concentrations...") )
                
            }
            
        } else {
            
        }
        
        df_Cons
        
    }
    # Now, to map this across all the dates, we can use purrr::map_df as follows:
    Capped_df <- rebalance_col %>%
        # Split our df into groups (where the groups here are the rebalance dates:
        group_split(RebalanceTime) %>%
        # Apply the function Proportional_Cap_Foo to each rebalancing date:
        map_df(~Proportional_Cap_Foo(., W_Cap = w_cap)) %>% select(-RebalanceTime)
    
    wts <- Capped_df %>%
        tbl_xts(cols_to_xts = weight, spread_by = Tickers)
    
    rts <- data %>%
        filter(Tickers %in% unique(Capped_df$Tickers)) %>%
        tbl_xts(cols_to_xts = Return, spread_by = Tickers)
    
    wts[is.na(wts)] <- 0
    rts[is.na(rts)] <- 0
    
    Idx <- rmsfuns::Safe_Return.portfolio(R = rts, weights = wts, lag_weights = TRUE) %>%
        # Let's make this a tibble:
        xts_tbl() %>%
        rename({{ fund_name }} := "portfolio.returns")
    
    return(Idx)
}

#now use the function to get the returns and get ready to "plot this bugga"
alsi_5 <- rebalance_returns(clean_ALSI , J203, w_cap = 0.05) %>% 
    rename("ALSI"= "J203") %>% 
    mutate(Index = "5%")

alsi_10 <- rebalance_returns(clean_ALSI , J203, w_cap = 0.10) %>% 
    rename("ALSI"= "J203") %>% 
    mutate(Index = "10%")

swix_5 <- rebalance_returns(clean_ALSI, J403, w_cap = 0.05) %>% 
    rename("SWIX"= "J403") %>% 
    mutate(Index = "5%")

swix_10 <- rebalance_returns(clean_ALSI, J403, w_cap = 0.1) %>% 
    rename("SWIX"= "J403") %>% 
    mutate(Index = "10%")

# Combine ALSI data frames
alsi_combined <- bind_rows(
    alsi_5 %>% select(date, ALSI, Index),
    alsi_10 %>% select(date, ALSI, Index)
)

# Combine SWIX data frames
swix_combined <- bind_rows(
    swix_5 %>% select(date, SWIX, Index),
    swix_10 %>% select(date, SWIX, Index)
)

# Merge ALSI and SWIX data frames based on the "date" column
idx <- full_join(alsi_combined, swix_combined, by = c("date","Index")) %>% 
    select(date, SWIX, ALSI, Index)


```


The figure illustrates that ALSI is more sensitive to the imposition of capping constraints compared to SWIX. Despite this higher susceptibility, ALSI consistently outperforms SWIX across all three restrictions.

This implies that even with the imposition of constraints, ALSI manages to maintain better performance than SWIX. The sensitivity of ALSI to these restrictions suggests it might require more nuanced management or adjustments to adhere to certain limitations without compromising its performance.
```{r}
# Let's plot 
idx %>% 
    mutate(swix = cumprod(1+SWIX)) %>% 
    mutate(alsi = cumprod(1+ALSI)) %>% 
    
    ggplot(., aes(x = date)) +
    geom_line(aes(y = alsi, color = "ALSI"), size = 1) +
    geom_line(aes(y = swix, color = "SWIX"), size = 1) +
    facet_wrap(~Index, scales = "free_y", ncol = 1) +
    labs(title = "ALSI and SWIX Over Time", x = "Date", y = "Value") +
    scale_color_manual(values = c(ALSI = "lightgreen", SWIX = "pink"))
  

```

<!-- The following is a code chunk. It must have its own unique name (after the r), or no name. After the comma follows commands for R which are self-explanatory. By default, the code and messages will not be printed in your pdf, just the output: -->



<!-- :::::: {.columns data-latex="[T]"} -->
<!-- ::: {.column data-latex="{0.7\textwidth}"} -->
<!-- ```{r, echo=FALSE, fig.width=4, fig.height=4} -->
<!-- par(mar = c(4, 4, .2, .1)) -->
<!-- plot(cars, pch = 19) -->
<!-- ``` -->
<!-- ::: -->
<!-- ::: {.column data-latex="{0.05\textwidth}"} -->
<!-- \ -->
<!-- ::: -->
<!-- ::: {.column data-latex="{0.2\textwidth}"} -->
<!-- \scriptsize -->

<!-- ## Data {-} -->
<!-- The figure on the left-hand side shows the `cars` data. -->

<!-- Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do -->
<!-- eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut -->
<!-- enim ad minim veniam, quis nostrud exercitation ullamco laboris -->
<!-- nisi ut aliquip ex ea commodo consequat. -->
<!-- ::: -->
<!-- :::::: -->


<!-- $$ -->
<!-- This is a commented out section in the writing part. -->
<!-- Comments are created by highlighting text, amnd pressing CTL+C -->
<!-- \\begin{align} -->
<!-- \\beta = \\alpha^2 -->
<!-- \end{align} -->
<!-- $$ -->




\hfill

<!-- hfill can be used to create a space, like here between text and table. -->





<!-- Make title of bibliography here: -->
<!-- \newpage -->

\newpage

<!-- # References {-} -->

<!-- <div id="refs"></div> -->


<!-- # Appendix {-} -->

<!-- ## Appendix A {-} -->

<!-- Some appendix information here -->

<!-- ## Appendix B {-} -->



